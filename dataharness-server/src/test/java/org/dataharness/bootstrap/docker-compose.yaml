version: '3.8'

networks:
  kafka-net:
    driver: bridge

services:
  kafka:
    image: confluentinc/cp-kafka:8.0.3
    container_name: kafka
    networks:
      - kafka-net
    ports:
      - "9092:9092"
    environment:
      CLUSTER_ID: MkQkQzAyNzA0NzgxNjEyNWRm
      KAFKA_KRAFT_MODE: "true"
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:9093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_LISTENERS: CONTROLLER://kafka:9093
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 1


  schema-registry:
    image: confluentinc/cp-schema-registry:8.0.3
    container_name: schema-registry
    depends_on:
      - kafka
    networks:
      - kafka-net
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: localhost
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092

  minio:
    image: minio/minio:latest
    container_name: minio
    networks:
      - kafka-net
    ports:
      - "9000:9000"
      - "9002:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3

  gravitino-iceberg-rest:
    image: apache/gravitino-iceberg-rest:latest
    container_name: gravitino-iceberg-rest
    depends_on:
      - minio
    networks:
      - kafka-net
    ports:
      - "9001:9001"
    environment:
      AWS_S3_ENDPOINT: http://minio:9000
      AWS_S3_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin

  postgres:
    build:
      context: .
      dockerfile: Dockerfile.postgres
    container_name: postgres
    networks:
      - kafka-net
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: dataharness
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres

  yugabytedb:
    image: yugabytedb/yugabyte:2025.2.0.0-b131
    container_name: yugabytedb
    networks:
      - kafka-net
    ports:
      - "17000:7000"
      - "19000:9000"
      - "15433:15433"
      - "5433:5433"
      - "19042:9042"
    command: bin/yugabyted start --background=false

  data-harness:
    image: data-harness:latest
    container_name: data-harness
    depends_on:
      - postgres
    networks:
      - kafka-net
    ports:
      - "50051:50051"

  trino:
    build:
      context: ../../../../../../../
      dockerfile: dataharness-server/src/test/java/org/dataharness/bootstrap/Dockerfile.trino
    container_name: trino
    depends_on:
      - kafka
      - schema-registry
      - minio
      - gravitino-iceberg-rest
      - postgres
      - yugabytedb
      - data-harness
    networks:
      - kafka-net
    ports:
      - "8080:8080"
    volumes:
      - ./etc/catalog/kafka.properties:/etc/trino/catalog/kafka.properties:ro
      - ./etc/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties:ro
      - ./etc/catalog/postgresql.properties:/etc/trino/catalog/postgresql.properties:ro
      - ./etc/catalog/data_harness.properties:/etc/trino/catalog/data_harness.properties:ro

  spark:
    image: apache/spark:latest
    container_name: spark
    depends_on:
      - kafka
      - schema-registry
      - minio
      - gravitino-iceberg-rest
      - postgres
      - yugabytedb
      - data-harness
    networks:
      - kafka-net
    ports:
      - "15002:15002"
      - "4040:4040"
    environment:
      AWS_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    tmpfs:
      - /nonexistent
    volumes:
      - ../../../../../../../dataharness-spark/target/dataharness-spark-1.0-SNAPSHOT.jar:/app/jars/dataharness-spark-1.0-SNAPSHOT.jar:ro
      - ../../../../../../../dataharness-rpc/target/dataharness-rpc-1.0-SNAPSHOT.jar:/app/jars/dataharness-rpc-1.0-SNAPSHOT.jar:ro
    command:
      - /opt/spark/bin/spark-submit
      - --class
      - org.apache.spark.sql.connect.service.SparkConnectServer
      - --jars
      - /app/jars/dataharness-spark-1.0-SNAPSHOT.jar,/app/jars/dataharness-rpc-1.0-SNAPSHOT.jar
      - --packages
      - org.apache.spark:spark-sql-kafka-0-10_2.13:4.1.0,org.apache.spark:spark-avro_2.13:4.1.0,org.postgresql:postgresql:42.7.3,org.apache.iceberg:iceberg-spark-runtime-4.0_2.13:1.10.0,org.apache.hadoop:hadoop-aws:3.4.0,com.amazonaws:aws-java-sdk-bundle:1.12.780,io.grpc:grpc-netty-shaded:1.77.0,io.grpc:grpc-protobuf:1.77.0,io.grpc:grpc-stub:1.77.0,com.google.protobuf:protobuf-java:4.31.1
      - --conf
      - spark.sql.catalog.gravitino=org.apache.iceberg.spark.SparkCatalog
      - --conf
      - spark.sql.catalog.gravitino.uri=http://gravitino-iceberg-rest:9001/iceberg
      - --conf
      - spark.sql.catalog.gravitino.type=rest
      - --conf
      - spark.sql.catalog.gravitino.s3.access-key-id=minioadmin
      - --conf
      - spark.sql.catalog.gravitino.s3.secret-access-key=minioadmin
      - --conf
      - spark.sql.catalog.gravitino.s3.endpoint=http://minio:9000
      - --conf
      - spark.sql.catalog.gravitino.s3.path-style-access=true
      - --conf
      - spark.sql.catalog.harness=org.dataharness.spark.DataHarnessCatalog
      - --conf
      - spark.sql.catalog.harness.data-harness-host=data-harness
      - --conf
      - spark.sql.catalog.harness.data-harness-port=50051
      - --conf
      - spark.sql.extensions=org.dataharness.spark.DataHarnessExtension
      - --conf
      - spark.hadoop.fs.s3a.access.key=minioadmin
      - --conf
      - spark.hadoop.fs.s3a.secret.key=minioadmin
      - --conf
      - spark.hadoop.fs.s3a.endpoint=http://minio:9000
      - --conf
      - spark.hadoop.fs.s3a.region=us-east-1
      - --conf
      - spark.hadoop.fs.s3a.path.style.access=true
      - --conf
      - spark.hadoop.fs.s3a.connection.ssl.enabled=false
      - --conf
      - spark.hadoop.fs.s3a.impl.disable.cache=true
      - --name
      - spark-connect-server
